{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOyPthIszS4cnj0mXNNxuR1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-soeiro/IntroPython-UERJ/blob/master/Projetos/Projeto2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYVgVEzvScbl"
      },
      "source": [
        "# **Projeto 2**\r\n",
        "\r\n",
        "##**Montagem de uma Rede Neural usando a arquitetura Perceptron**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrPeTEeZuH03"
      },
      "source": [
        "**Autores** Gabriela Gonçalves, Úrsula Goulart e Victor Soeiro.\r\n",
        "\r\n",
        "[Arquivo do Projeto](https://github.com/malbouis/Python_intro/blob/master/aulas/projetos/projeto2_perceptrons.ipynb)\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW-jLMHUSby7"
      },
      "source": [
        "Um Perceptron é uma arquitetura binária de Redes Neurais que utiliza apenas uma camada de processamento, ou melhor, apenas um neurônio. Esse neurônio utiliza uma função de ativação para o processamos do somatório dos inputs com seus pesos e retorna um output, também binário."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuf-W8GKzU9F"
      },
      "source": [
        "<img src=\"https://images.deepai.org/glossary-terms/perceptron-6168423.jpg\" width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcoB1IsezVnY"
      },
      "source": [
        "Para o projeto, vamos utilizar a função de ativação *Heaviside StepFunction*. Em linguagem Python, poderiamos escrevê-la como,\r\n",
        "\r\n",
        "```\r\n",
        "def heaviside(summation, b):\r\n",
        "    return 1 if summation > b else 0\r\n",
        "```\r\n",
        "\r\n",
        "Onde, b nomeamos como bias. \r\n",
        "\r\n",
        "Essa desigualdade pode ser escrita em relação do somatório dos inputs com os pesos mais o bias, sendo agora maior ou menor que zero. \r\n",
        "\r\n",
        "Portanto,\r\n",
        "\r\n",
        "$ \\phi(x) = \r\n",
        "\\begin{cases}\r\n",
        "   1 & \\text{se $\\sum_{i}^{N} x_i \\omega_i + b > 0$} \\\\\r\n",
        "   0 & \\text{se $\\sum_{i}^{N} x_i \\omega_i + b \\leq 0$}\r\n",
        "\\end{cases}$\r\n",
        "\r\n",
        "Para incorporar o bias no somatório, o chamaremos de peso zero, $\\omega_0$, com um input, $x_0$, igual a 1. \r\n",
        "\r\n",
        "**Obs.:** O produto dos pesos com os inputs é um produto matricial devido serem arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0ie7sNbny6S"
      },
      "source": [
        "Para cada conjunto de inputs do Perceptron, que chamaremos de features, compararemos o output, chamado de y, com o valor do dataset, chamado de label. A partir dessas comparaçãos, ajustaremos os pesos até que tenha a menor diferença para uma melhor classificação do Perceptron. \r\n",
        "\r\n",
        "```\r\n",
        "w = w + learning_rate * (label - y) * x\r\n",
        "```\r\n",
        "\r\n",
        "Onde, o *learning_rate* é a taxa de aprendizado do Perceptron.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02lbOhBapaEK"
      },
      "source": [
        "Vamos começar a programação do Perceptron importando o módulo Numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns1HEUqJoOur"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "294FJ_vySczu"
      },
      "source": [
        "Iremos criar uma classe para o Perceptron e definir duas funções essenciais, *predict* e *train*. Portanto,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POy_sY2VDSa-"
      },
      "source": [
        "class Perceptron:\r\n",
        "    def __init__(self, n_of_inputs, threshold=100, learning_rate=.01):\r\n",
        "        self.bias = 0\r\n",
        "        self.weights = np.zeros(n_of_inputs)\r\n",
        "        self.threshold = threshold\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "\r\n",
        "    def predict(self, inputs):\r\n",
        "        return np.heaviside(np.dot(inputs, self.weights) + self.bias, 0)\r\n",
        "\r\n",
        "    def train(self, training_inputs, labels):\r\n",
        "        for _ in range(self.threshold):\r\n",
        "            for n in range(len(training_inputs)):\r\n",
        "                prediction = self.predict(training_inputs[n])\r\n",
        "                self.weights += self.learning_rate * (labels[n] - prediction) * training_inputs[n]\r\n",
        "                self.bias += self.learning_rate * (labels[n] - prediction)\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI7_GFKHV-ZR"
      },
      "source": [
        "O módulo sklearn possui vários datasets para o teste de redes neurais e aprendizado de máquinas. Portanto, o usaremos para importar o dataset dos dados da flor iris e, também, a sua classe Perceptron para comparação com a classe criada acima."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUe3O0NbWKSf"
      },
      "source": [
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.linear_model import Perceptron as sklearn_perceptron\r\n",
        "\r\n",
        "iris = load_iris()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4mFJdorWRaa"
      },
      "source": [
        "Vamos ver as features das flores iris."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmjs5VViWW_I",
        "outputId": "05fa47f2-8586-4650-f627-bbd6c5d13660"
      },
      "source": [
        "print(iris.target_names)\r\n",
        "print(iris.feature_names)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO7fevPEWbWl"
      },
      "source": [
        "Para o projeto usaremos apenas as features *petal length* e *petal width*. Vamos criar um variável *x* para carregar uma array com 150 conjunto de inputs com as features selecionadas e uma variável *y* para carregar os output esperados para uma Iris-Setosa, onde 0 é não e 1 é sim."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYJQJg3cRIGQ"
      },
      "source": [
        "x = iris.data[:, (2, 3)]\r\n",
        "y = (iris.target == 0).astype(int)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G2pVF7xWr1P"
      },
      "source": [
        "Rodando o nosso Perceptron para duas features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtsPij48Wu58",
        "outputId": "6e18189b-3f0c-4262-8041-388aae1b3c52"
      },
      "source": [
        "perceptron = Perceptron(2)\r\n",
        "\r\n",
        "train = perceptron.train(x, y)\r\n",
        "predict = perceptron.predict([1, 0.5])\r\n",
        "\r\n",
        "print(predict)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQAlIkSEUjKk"
      },
      "source": [
        "Rodando o Perceptron do módulo sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om4AeSp0WwAh",
        "outputId": "6827baf7-7c84-4c8d-e416-5f66f48de031"
      },
      "source": [
        "perceptron_clf = sklearn_perceptron()\r\n",
        "perceptron_clf.fit(x, y)\r\n",
        "\r\n",
        "y_pred = perceptron_clf.predict([[1, 0.5]])\r\n",
        "print(y_pred)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-yiOZlMXLmc"
      },
      "source": [
        "Portanto, vemos que o nosso Perceptron resulta no mesmo valor do Perceptron do módulo sklearn. Por curiosidade, vamos realizar mais um teste, porém para a Iris-Virginica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU4m-kzlXY3_"
      },
      "source": [
        "x = iris.data[:, (2, 3)]\r\n",
        "y = (iris.target == 2).astype(int)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MerqERFlscIl",
        "outputId": "485c563c-7353-4222-ae7d-be3b37a1ceef"
      },
      "source": [
        "perceptron_virginica = Perceptron(2)\r\n",
        "\r\n",
        "train = perceptron_virginica.train(x, y)\r\n",
        "predict = perceptron_virginica.predict([1, 0.5])\r\n",
        "\r\n",
        "print(predict)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtojyFTCsulC",
        "outputId": "d8131c29-00d7-4ca5-fc15-e702bd574a72"
      },
      "source": [
        "perceptron_clf_virginica = sklearn_perceptron()\r\n",
        "perceptron_clf_virginica.fit(x, y)\r\n",
        "\r\n",
        "y_pred = perceptron_clf_virginica.predict([[1, 0.5]])\r\n",
        "print(y_pred)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDJLhm4HXrtc"
      },
      "source": [
        "Como a predição foi usado o mesmo valor que retornou verdadeiro para a Iris-Setosa, retornou falso para a Iris-Virginica, como esperado.\r\n",
        "\r\n",
        "O Perceptron torna-se uma arquitetura de redes neurais interessante ao trabalhar com classificações binárias e linearmente separáveis, como a o ajuste linear de uma reta.\r\n",
        "\r\n",
        "O algoritmo do Perceptron começa a falhar quando o dataset para o seu aprendizado não é linearmente separável, tal que, não conseguirá classificar o dataset corretamente. Outra limitação é a classificação binária, na qual nem todos casos torna-se aplicável."
      ]
    }
  ]
}